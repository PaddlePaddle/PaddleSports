# 基于骨骼点进行体育场景动作识别（都以花样滑冰为例）



该数据集来自于[2021 CCF BDCI 基于飞桨实现花样滑冰选手骨骼点动作识别]([2021 CCF BDCI 基于飞桨实现花样滑冰选手骨骼点动作识别 - 飞桨AI Studio (baidu.com)](https://aistudio.baidu.com/aistudio/competition/detail/115/0/introduction))，本赛题数据集旨在通过花样滑冰研究人体的运动。在花样滑冰运动中，人体姿态和运动轨迹相较于其他运动呈现复杂性强、类别多的特点，有助于细粒度图深度学习新模型、新任务的研究。

在数据集中，所有的视频素材从2017 到2018 年的花样滑冰锦标赛中采集。源视频素材中视频的帧率被统一标准化至每秒30 帧，并且图像大小是1080 * 720 来保证数据集的相对一致性。之后通过2D姿态估计算法Open Pose对视频进行逐帧骨骼点提取，最后以.npy格式保存数据集。



模型从先到后为ST-GCN,AGCN-2S,AAGCN,CTR-GCN。

ST-GCN是AAAI 2018提出的经典的基于骨骼的行为识别模型，通过将图卷积应用在具有拓扑结构的人体骨骼数据上，使用时空图卷积提取时空特征进行行为识别，极大地提升了基于骨骼的行为识别任务精度。AGCN-2S公开发表于2019.7，是对于ST-GCN的改进。AAGCN是在AGCN-2S论文之后2019.12同作者进行的改进，CTR-GCN是在2021年8月份发表的论文。

