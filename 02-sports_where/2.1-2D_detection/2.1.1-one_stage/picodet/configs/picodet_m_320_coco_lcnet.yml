# norm
weights: output/Picodet/best_model
find_unused_parameters: True
use_ema: true
snapshot_epoch: 300

# datasets

metric: COCO
num_classes: 80

TrainDataset:
  COCODataSet:
    # use val data fo test
    image_dir: val2017
    anno_path: annotations/instances_val2017.json
    dataset_dir: ../
    data_fields: ['image', 'gt_bbox', 'gt_class', 'is_crowd']

EvalDataset:
  COCODataSet:
    image_dir: val2017
    anno_path: annotations/instances_val2017.json
    dataset_dir: ../

TestDataset:
  ImageFolder:
    anno_path: annotations/instances_val2017.json # also support txt (like VOC's label_list.txt)
    dataset_dir: datasets/coco # if set, anno_path will be 'dataset_dir/anno_path'

# reader

worker_num: 6
eval_height: &eval_height 320
eval_width: &eval_width 320
eval_size: &eval_size [*eval_height, *eval_width]

TrainReader:
  sample_transforms:
  - Decode: {}
  - RandomCrop: {}
  - RandomFlip: {prob: 0.5}
  - RandomDistort: {}
  batch_transforms:
  - BatchRandomResize: {target_size: [256, 288, 320, 352, 384], random_size: True, random_interp: True, keep_ratio: False}
  - NormalizeImage: {is_scale: true, mean: [0.485,0.456,0.406], std: [0.229, 0.224,0.225]}
  - Permute: {}
  - PadGT: {}
  batch_size: 32
  shuffle: true
  drop_last: true


EvalReader:
  sample_transforms:
  - Decode: {}
  - Resize: {interp: 2, target_size: *eval_size, keep_ratio: False}
  - NormalizeImage: {is_scale: true, mean: [0.485,0.456,0.406], std: [0.229, 0.224,0.225]}
  - Permute: {}
  batch_transforms:
  - PadBatch: {pad_to_stride: 32}
  batch_size: 8
  shuffle: false


TestReader:
  inputs_def:
    image_shape: [1, 3, *eval_height, *eval_width]
  sample_transforms:
  - Decode: {}
  - Resize: {interp: 2, target_size: *eval_size, keep_ratio: False}
  - NormalizeImage: {is_scale: true, mean: [0.485,0.456,0.406], std: [0.229, 0.224,0.225]}
  - Permute: {}
  batch_size: 1


# runtime

use_gpu: true
use_xpu: false
log_iter: 20
save_dir: output
filename: Picodet
print_flops: false

# Exporting the model
export:
  post_process: True  # Whether post-processing is included in the network when export model.
  nms: True           # Whether NMS is included in the network when export model.
  benchmark: False    # It is used to testing model performance, if set `True`, post-process and NMS will not be exported.


# architecture
architecture: PicoDet
pretrain_weights: https://paddledet.bj.bcebos.com/models/pretrained/LCNet_x1_5_pretrained.pdparams

PicoDet:
  backbone:
    LCNet:
      scale: 1.5
      feature_maps: [ 3, 4, 5 ]
  neck:
    LCPAN:
      out_channels: 128
      use_depthwise: True
      num_features: 4
  head:
    PicoHeadV2:
      conv_feat:
        name: PicoFeat
        feat_in: 128
        feat_out: 128
        num_convs: 4
        num_fpn_stride: 4
        norm_type: bn
        share_cls_reg: True
        use_se: True
      fpn_stride: [ 8, 16, 32, 64 ]
      feat_in_chan: 128
      prior_prob: 0.01
      reg_max: 7
      cell_offset: 0.5
      grid_cell_scale: 5.0
      static_assigner_epoch: 100
      use_align_head: True
      static_assigner:
        name: ATSSAssigner
        topk: 9
        force_gt_matching: False
      assigner:
        name: TaskAlignedAssigner
        topk: 13
        alpha: 1.0
        beta: 6.0
      loss_class:
        name: VarifocalLoss
        use_sigmoid: False
        iou_weighted: True
        loss_weight: 1.0
      loss_dfl:
        name: DistributionFocalLoss
        loss_weight: 0.5
      loss_bbox:
        name: GIoULoss
        loss_weight: 2.5
      nms:
        name: MultiClassNMS
        nms_top_k: 1000
        keep_top_k: 100
        score_threshold: 0.025
        nms_threshold: 0.6


# optimizer

epoch: 300

LearningRate:
  base_lr: 0.08
  schedulers:
  - CosineDecay:
      max_epochs: 300
  - LinearWarmup:
      start_factor: 0.1
      steps: 300

OptimizerBuilder:
  optimizer:
    momentum: 0.9
    type: Momentum
  regularizer:
    factor: 0.00004
    type: L2